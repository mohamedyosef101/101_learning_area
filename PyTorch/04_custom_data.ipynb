{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedyosef101/101_learning_area/blob/area/PyTorch/04_custom_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom** Dataset\n",
        "**source**: the original notebook created by [Daniel Bourke](https://www.learnpytorch.io/04_pytorch_custom_datasets/)"
      ],
      "metadata": {
        "id": "PWyy7nJXclao"
      },
      "id": "PWyy7nJXclao"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader as dl\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Available device:\", device)"
      ],
      "metadata": {
        "id": "nhwwkx1qdAKA"
      },
      "id": "nhwwkx1qdAKA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Get** the data"
      ],
      "metadata": {
        "id": "ZNXgrG67ddlG"
      },
      "id": "ZNXgrG67ddlG"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# if the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} dirctory exists.\")\n",
        "else:\n",
        "  print(f\"Did not find {image_path} directory, creating one...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # download pizza, steak, sushi data\n",
        "  with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading pizza, steak, sushi data...\")\n",
        "    f.write(request.content)\n",
        "\n",
        "  # unzip pizza, steak, sushi data\n",
        "  with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak, sushi data...\")\n",
        "    zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "9WTVAzSodh-k"
      },
      "id": "9WTVAzSodh-k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how the data looks like:\n",
        "\n",
        "```\n",
        "pizza_steak_sushi/ <- overall dataset folder\n",
        "    train/ <- training images\n",
        "        pizza/ <- class name as folder name\n",
        "            image01.jpeg\n",
        "            image02.jpeg\n",
        "            ...\n",
        "        steak/\n",
        "            image24.jpeg\n",
        "            image25.jpeg\n",
        "            ...\n",
        "        sushi/\n",
        "            image37.jpeg\n",
        "            ...\n",
        "    test/ <- testing images\n",
        "        pizza/\n",
        "            image101.jpeg\n",
        "            image102.jpeg\n",
        "            ...\n",
        "        steak/\n",
        "            image154.jpeg\n",
        "            image155.jpeg\n",
        "            ...\n",
        "        sushi/\n",
        "            image167.jpeg\n",
        "            ...\n",
        "```"
      ],
      "metadata": {
        "id": "vPI2g5nfgRfA"
      },
      "id": "vPI2g5nfgRfA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data **Preparation**"
      ],
      "metadata": {
        "id": "SAldwGvRgbBe"
      },
      "id": "SAldwGvRgbBe"
    },
    {
      "cell_type": "code",
      "source": [
        "### walk through the data ###\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and \" +\n",
        "          f\"{len(filenames)} images in `{dirpath}`.\")\n",
        "\n",
        "# call it\n",
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "ECPptKAmgun5"
      },
      "id": "ECPptKAmgun5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup train and test paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\""
      ],
      "metadata": {
        "id": "7lcYsPSqiDrf"
      },
      "id": "7lcYsPSqiDrf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize an image"
      ],
      "metadata": {
        "id": "XuhEAlTvzmC-"
      },
      "id": "XuhEAlTvzmC-"
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# set seed\n",
        "random.seed(7)\n",
        "\n",
        "# 1. Get all image paths\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "# 2. Get random image path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "\n",
        "# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "# 4. Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# 5. Print metadata\n",
        "print(f\"Random image path: {random_image_path}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\")\n",
        "print(f\"Image width: {img.width}\")\n",
        "\n",
        "# display the image\n",
        "img"
      ],
      "metadata": {
        "id": "Y06eMI-civss"
      },
      "id": "Y06eMI-civss",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# do the same with imshow()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Turn the image into an array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "# Plot the image with matplotlib\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_as_array)\n",
        "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color_channels]\")\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "34R3HDHTjhAC"
      },
      "id": "34R3HDHTjhAC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transforming data"
      ],
      "metadata": {
        "id": "6cfZ1_co0BNv"
      },
      "id": "6cfZ1_co0BNv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several different kinds of pre-built datasets and dataset loaders for PyTorch, depending on the problem you're working on.\n",
        "\n",
        "| Problem space | Pre-built Datasets and Functions |\n",
        "| --- | --- |\n",
        "| Vision | [`torchvision.datasets`](https://pytorch.org/vision/stable/datasets.html) |\n",
        "| Audio | [`torchaudio.datasets`](https://pytorch.org/audio/stable/datasets.html) |\n",
        "| Text | [`torchtext.datasets`](https://pytorch.org/text/stable/datasets.html) |\n",
        "| Recommendation system | [`torchrec.datasets`](https://pytorch.org/torchrec/torchrec.datasets.html) |\n",
        "\n",
        "Since we're working with a vision problem, we'll be looking at `torchvision.datasets` for our data loading functions as well as [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html) for preparing our data."
      ],
      "metadata": {
        "id": "Hu4F5jj60gZM"
      },
      "id": "Hu4F5jj60gZM"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}